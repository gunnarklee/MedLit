{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Script to parse our XML documents for porting into a graph database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "We have 6 total records\n",
      "This process took 0.00102591514587 seconds\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import time\n",
    "import sys\n",
    "import string\n",
    "\n",
    "'''The following will cause the iPython notebook to stop printing within\n",
    "the document!!  You will still see it in the terminal.  Was the easiest\n",
    "way to get rid of all the utf-8 encoding errors so I kept it.'''\n",
    "#reload(sys)\n",
    "#sys.setdefaultencoding('utf-8')\n",
    "\n",
    "\n",
    "'''First step is to walk through our directory to find all the filenames'''\n",
    "#So we can measure duration\n",
    "start = time.time()\n",
    "\n",
    "#What we append to\n",
    "fileSet = set()\n",
    "\n",
    "#Just walks through all the files in PMC_Files and appends filenames to fileSet\n",
    "for dir_, _, files in os.walk(\"./PMC_Files\"):\n",
    "    for fileName in files:\n",
    "        relDir = os.path.relpath(dir_, \"./\")\n",
    "        relFile = os.path.join(relDir, fileName)\n",
    "        fileSet.add(relFile)\n",
    "\n",
    "stop = time.time()\n",
    "duration = stop - start\n",
    "\n",
    "print \"We have %s total records\" %(len(fileSet))\n",
    "print \"This process took %s seconds\" %(duration)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from xml.dom import minidom as md\n",
    "import csv\n",
    "\n",
    "\n",
    "\n",
    "def removePunctuation(s):\n",
    "    exclude = set(string.punctuation)\n",
    "    return ''.join(ch for ch in s if ch not in exclude)\n",
    "\n",
    "def parseXML(data):\n",
    "    '''Takes XML input and extracts several relevant fields. Note that right now\n",
    "    this uses a lot of IO, as we write to the csv file for every article.\n",
    "    Optimization possible.'''\n",
    "    xmldoc = md.parse(data)\n",
    "\n",
    "    #Establish basic XML tree structure.  I find this easier to use than ElementTree\n",
    "    #This allows us to drill down to individual trees later\n",
    "    jmeta = xmldoc.getElementsByTagName(\"journal-meta\")[0]\n",
    "    ameta = xmldoc.getElementsByTagName(\"article-meta\")[0]\n",
    "\n",
    "    #Get journal title\n",
    "    jtitle = jmeta.getElementsByTagName(\"journal-title\")[0].firstChild.data\n",
    "    \n",
    "    #Get Pubmed ID (\"pmid\"), article title, contributors\n",
    "    '''Getting the pubmed ID is a little cumbersome. Its not always in the same\n",
    "    location under article-id so we cant just pull from a direct node. While there\n",
    "    is a unique type for each ID, I wasnt able to figure out how to select it.\n",
    "    Pubmed IDs appear to be the only ones that are 8 characters long, so I just\n",
    "    iterated through IDs instead.  This may cause problems if another ID type\n",
    "    also has 8 characters and appears before \"pmid\" - though I didnt see any.'''\n",
    "    a_id = ameta.getElementsByTagName(\"article-id\")\n",
    "    for ids in a_id:\n",
    "        id_val = ids.firstChild.data\n",
    "        if len(id_val) == 8:\n",
    "            pubmedID = id_val\n",
    "            break\n",
    "    \n",
    "    #Get Article Title\n",
    "    '''Theres a problem here - if the journal used italics or bold and its tagged that\n",
    "    way then it creates a whole separate element, breaking up the normal title flow.\n",
    "    I tried multiple ways of fixing it but couldnt find any that worked.  As of now\n",
    "    we simply exclude these from the dataset.  Its a minority of documents for sure, but\n",
    "    still something I would like to have fixed.  This probably means were biasing\n",
    "    against certain journals.'''\n",
    "    atitle = ameta.getElementsByTagName(\"article-title\")[0].firstChild.data\n",
    "    \n",
    "    #get the PMC Release year - change to 0 for nihms-submitted and 1 for ppub\n",
    "    '''Note: given the issue with Pubmed IDs, this may also provide years from other tags.\n",
    "    I havent researched it to find out.'''\n",
    "    pubdate = ameta.getElementsByTagName(\"pub-date\")[0]\n",
    "    year = pubdate.getElementsByTagName(\"year\")[0].firstChild.data\n",
    "    \n",
    "    #get contributors\n",
    "    c_group = ameta.getElementsByTagName(\"contrib-group\")[0]\n",
    "    contributor = c_group.getElementsByTagName(\"contrib\")\n",
    "    \n",
    "    #Open the output file\n",
    "    outputFile = open(\"output2.csv\",'a')\n",
    "    wr = csv.writer(outputFile)\n",
    "    \n",
    "    #Cycle through to get all contributors\n",
    "    for person in contributor:\n",
    "        \n",
    "        #If element contains names, use those\n",
    "        try:\n",
    "            lastname = person.getElementsByTagName(\"surname\")[0].firstChild.data\n",
    "            firstname = person.getElementsByTagName(\"given-names\")[0].firstChild.data\n",
    "        \n",
    "        #Businesses use 'collab' instead of names\n",
    "        except IndexError:   \n",
    "            firstname = person.getElementsByTagName(\"collab\")[0].firstChild.data\n",
    "            lastname=\"\"\n",
    "\n",
    "        fullname = firstname+\" \"+lastname              \n",
    "        \n",
    "        fullname = removePunctuation(fullname)\n",
    "        atitle = removePunctuation(atitle)\n",
    "        pubmedID = removePunctuation(pubmedID)\n",
    "        jtitle = removePunctuation(jtitle)\n",
    "        \n",
    "        #Output\n",
    "        csvline = [fullname,atitle,pubmedID,jtitle,year]\n",
    "        wr.writerow(csvline)\n",
    "    \n",
    "    #Close output file when for loop completes\n",
    "    outputFile.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PMC_Files/Zoonoses_Public_Health_2015_Mar_7_62(2)_131-140.nxml\n",
      "PMC_Files/Zoonoses_Public_Health_2015_Apr_22_62(Suppl_1)_10-21.nxml\n",
      "PMC_Files/.DS_Store\n",
      "Unknown Error in PMC_Files/.DS_Store\n",
      "PMC_Files/Zoonoses_Public_Health_2016_Mar_3_63(2)_112-128.nxml\n",
      "PMC_Files/Zoonoses_Public_Health_2014_May_19_61(3)_157-166.nxml\n",
      "PMC_Files/Zoonoses_Public_Health_2014_Jun_17_61(4)_271-282.nxml\n",
      "Processing completed in 0.253264188766 seconds\n",
      "output.csv file was generated in the same directory as this python script.\n",
      "\n",
      "5 successes. 1 failures.\n"
     ]
    }
   ],
   "source": [
    "'''Takes a LONG time'''\n",
    "'''HEADS UP - I have an empty \"except\" argument so we can get through\n",
    "the entire list in one attempt without stalling every few hours for a\n",
    "one-off error.  This means that once you start this there is no stopping \n",
    "it unless you hard stop the iPython Notebook server (Control-C twice in terminal).\n",
    "Trying to \"Stop Kernel\" from within iPython will simply raise the\n",
    "Unknown Error condition and the script will continue on its merry way.'''\n",
    "\n",
    "start = time.time()\n",
    "\n",
    "successes = 0\n",
    "failures = 0\n",
    "\n",
    "for n in fileSet:\n",
    "    \n",
    "    #Using 'try' helps with debugging issues\n",
    "    try:\n",
    "        print n\n",
    "        parseXML(n)\n",
    "        successes += 1\n",
    "    \n",
    "    #The following catch errors, the most prevalent of which are AttributeErrors\n",
    "    except IndexError:\n",
    "        print \"IndexError in\", n\n",
    "        failures += 1\n",
    "    except AttributeError:\n",
    "        print \"AttributeError in\", n\n",
    "        failures += 1\n",
    "    except:\n",
    "        print \"Unknown Error in\", n\n",
    "        failures += 1\n",
    "    \n",
    "    try:\n",
    "        os.remove(\"./\"+n)\n",
    "    except:\n",
    "        print \"Failed to remove\", n\n",
    "        \n",
    "    #Just helps monitor what's happening\n",
    "    if successes%5000 == 0:\n",
    "        tempstop = time.time()\n",
    "        tempduration = (tempstop - start)/60\n",
    "        print \"%s successes, %s failures :: %s minutes\" %(successes,failures,tempduration)\n",
    "\n",
    "stop = time.time()\n",
    "duration = stop - start\n",
    "\n",
    "print \"Processing completed in %s seconds\"  %(duration)\n",
    "print \"output.csv file was generated in the same directory as this python script.\"\n",
    "print \"\"\n",
    "print \"%s successes. %s failures.\" %(successes, failures)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
