{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Script to parse our XML documents for porting into a graph database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "import sys\n",
    "\n",
    "'''The following will cause the iPython notebook to stop printing within\n",
    "the document!!  You will still see it in the terminal.  Was the easiest\n",
    "way to get rid of all the utf-8 encoding errors so I kept it.'''\n",
    "reload(sys)\n",
    "sys.setdefaultencoding('utf-8')\n",
    "\n",
    "\n",
    "'''First step is to walk through our directory to find all the filenames'''\n",
    "#So we can measure duration\n",
    "start = time.time()\n",
    "\n",
    "#What we append to\n",
    "fileSet = set()\n",
    "\n",
    "#Just walks through all the files in PMC_Files and appends filenames to fileSet\n",
    "for dir_, _, files in os.walk(\"./PMC_Files\"):\n",
    "    for fileName in files:\n",
    "        relDir = os.path.relpath(dir_, \"./\")\n",
    "        relFile = os.path.join(relDir, fileName)\n",
    "        fileSet.add(relFile)\n",
    "\n",
    "stop = time.time()\n",
    "duration = stop - start\n",
    "\n",
    "print \"We have %s total records\" %(len(fileSet))\n",
    "print \"This process took %s seconds\" %(duration)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from xml.dom import minidom as md\n",
    "import csv\n",
    "\n",
    "def parseXML(data):\n",
    "    '''Takes XML input and extracts several relevant fields. Note that right now\n",
    "    this uses a lot of IO, as we open, write, and close the csv file for every article.\n",
    "    Optimization possible.'''\n",
    "    xmldoc = md.parse(data)\n",
    "\n",
    "    #Establish basic XML tree structure.  I find this easier to use than ElementTree\n",
    "    #This allows us to drill down to individual trees later\n",
    "    jmeta = xmldoc.getElementsByTagName(\"journal-meta\")[0]\n",
    "    ameta = xmldoc.getElementsByTagName(\"article-meta\")[0]\n",
    "\n",
    "    #Get journal title\n",
    "    jtitle = jmeta.getElementsByTagName(\"journal-title\")[0].firstChild.data\n",
    "    \n",
    "    #Get Pubmed ID (\"pmid\"), article title, contributors\n",
    "    '''Getting the pubmed ID is a little cumbersome. Its not always in the same\n",
    "    location under article-id so we cant just pull from a direct node. While there\n",
    "    is a unique type for each ID, I wasnt able to figure out how to select it.\n",
    "    Pubmed IDs appear to be the only ones that are 8 characters long, so I just\n",
    "    iterated through IDs instead.  This may cause problems if another ID type\n",
    "    also has 8 characters and appears before \"pmid\" - though I didnt see any.'''\n",
    "    a_id = ameta.getElementsByTagName(\"article-id\")\n",
    "    for ids in a_id:\n",
    "        id_val = ids.firstChild.data\n",
    "        if len(id_val) == 8:\n",
    "            pubmedID = id_val\n",
    "            break\n",
    "    \n",
    "    #Get Article Title\n",
    "    '''Theres a problem here - if the journal used italics or bold and its tagged that\n",
    "    way then it creates a whole separate element, breaking up the normal title flow.\n",
    "    I tried multiple ways of fixing it but couldnt find any that worked.  As of now\n",
    "    we simply exclude these from the dataset.  Its a minority of documents for sure, but\n",
    "    still something I would like to have fixed.  This probably means were biasing\n",
    "    against certain journals.'''\n",
    "    atitle = ameta.getElementsByTagName(\"article-title\")[0].firstChild.data\n",
    "    \n",
    "    #get the PMC Release year - change to 0 for nihms-submitted and 1 for ppub\n",
    "    '''Note: given the issue with Pubmed IDs, this may also provide years from other tags.\n",
    "    I havent researched it to find out.'''\n",
    "    pubdate = ameta.getElementsByTagName(\"pub-date\")[2]\n",
    "    year = pubdate.getElementsByTagName(\"year\")[0].firstChild.data\n",
    "    \n",
    "    #get contributors\n",
    "    c_group = ameta.getElementsByTagName(\"contrib-group\")[0]\n",
    "    contributor = c_group.getElementsByTagName(\"contrib\")\n",
    "    \n",
    "    #Open the output file\n",
    "    outputFile = open(\"output.csv\",'a')\n",
    "    wr = csv.writer(outputFile)\n",
    "    \n",
    "    #Cycle through to get all contributors\n",
    "    for person in contributor:\n",
    "        \n",
    "        #If element contains names, use those\n",
    "        try:\n",
    "            lastname = person.getElementsByTagName(\"surname\")[0].firstChild.data\n",
    "            firstname = person.getElementsByTagName(\"given-names\")[0].firstChild.data\n",
    "        \n",
    "        #Businesses use 'collab' instead of names\n",
    "        except IndexError:   \n",
    "            firstname = person.getElementsByTagName(\"collab\")[0].firstChild.data\n",
    "            lastname=\"\"\n",
    "\n",
    "        fullname = firstname+\" \"+lastname      \n",
    "\n",
    "        #Output\n",
    "        csvline = [fullname,atitle,a_id,jtitle,year]\n",
    "        wr.writerow(csvline)\n",
    "    \n",
    "    #Close output file when for loop completes\n",
    "    outputFile.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "'''Takes a LONG time'''\n",
    "\n",
    "start = time.time()\n",
    "\n",
    "successes = 0\n",
    "failures = 0\n",
    "\n",
    "for n in fileSet:\n",
    "    \n",
    "    #Using 'try' helps with debugging issues\n",
    "    try:\n",
    "        parseXML(n)\n",
    "        successes += 1\n",
    "    \n",
    "    #The following catch errors, the most prevalent of which are AttributeErrors\n",
    "    except IndexError:\n",
    "        print \"IndexError in\", n\n",
    "        failures += 1\n",
    "    except AttributeError:\n",
    "        print \"AttributeError in\", n\n",
    "        failures += 1\n",
    "    except ExpatError:\n",
    "        print \"ExpatError in\", n\n",
    "        failures += 1\n",
    "    \n",
    "    #Just helps monitor what's happening\n",
    "    if successes%5000 == 0:\n",
    "        tempstop = time.time()\n",
    "        tempduration = (tempstop - start)/60\n",
    "        print \"%s successes, %s failures :: %s minutes\" %(successes,failures,tempduration)\n",
    "\n",
    "stop = time.time()\n",
    "duration = stop - start\n",
    "\n",
    "print \"Processing completed in %s seconds\"  %(duration)\n",
    "print \"output.csv file was generated in the same directory as this python script.\"\n",
    "print \"\"\n",
    "print \"$s successes. $s failures.\" %(successes, failures)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
